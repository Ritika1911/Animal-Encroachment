{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcdaa036",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import glob\n",
    "import datetime\n",
    "from collections import deque\n",
    "\n",
    "import IPython\n",
    "from pylab import *\n",
    "\n",
    "from skimage import img_as_float\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e895f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(r\"C:\\Users\\Likhita\\OneDrive - XLRI\\Desktop\\sem 7\\Project\\el.JPG\") \n",
    "\n",
    "cv2.imshow(\"framfr\",cv2.resize(img,None,fx=0.65,fy=0.65))\n",
    "cv2.waitKey(0)\n",
    " \n",
    "\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "img_blur = cv2.GaussianBlur(img_gray, (3,3), 0) \n",
    "\n",
    "sobelx = cv2.Sobel(src=img_blur, ddepth=cv2.CV_64F, dx=1, dy=0, ksize=5) \n",
    "sobely = cv2.Sobel(src=img_blur, ddepth=cv2.CV_64F, dx=0, dy=1, ksize=5) \n",
    "sobelxy = cv2.Sobel(src=img_blur, ddepth=cv2.CV_64F, dx=1, dy=1, ksize=5)\n",
    "\n",
    "cv2.imshow(sobelx)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow(sobely)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow( sobelxy)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2870ddca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12f88adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fb06025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\likhita\\anaconda3\\lib\\site-packages (4.7.0.72)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\likhita\\anaconda3\\lib\\site-packages (from opencv-python) (1.21.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9585195",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c027d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "006c9ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_animal = r\"C:\\Users\\Likhita\\OneDrive - XLRI\\Desktop\\animal-or-human\\train\\animals\"\n",
    "train_misc= r\"C:\\Users\\Likhita\\OneDrive - XLRI\\Desktop\\animal-or-human\\train\\humans\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b10a0eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dir = r\"C:\\Users\\Likhita\\OneDrive - XLRI\\Desktop\\animal-or-human\\validation\"\n",
    "train_dir = r\"C:\\Users\\Likhita\\OneDrive - XLRI\\Desktop\\animal-or-human\\train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9fc097a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1801\n"
     ]
    }
   ],
   "source": [
    "train_animal_names = os.listdir(train_animal)\n",
    "print(len(train_animal_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcccc6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 298, 298, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 149, 149, 16)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 147, 147, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 73, 73, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 71, 71, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 35, 35, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 33, 33, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 16, 16, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 14, 14, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 7, 7, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3136)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               1606144   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,704,097\n",
      "Trainable params: 1,704,097\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(300, 300, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df87bf92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Likhita\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\rmsprop.py:135: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(RMSprop, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=RMSprop(lr=0.001),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1c7e079",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\n",
    "valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c733aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2737 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen = train_datagen.flow_from_directory(train_dir,\n",
    "                                             target_size=(300,300),\n",
    "                                             class_mode='binary'\n",
    "                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a27e95b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_gen = train_datagen.flow_from_directory(\n",
    "    valid_dir,\n",
    "    target_size = (300,300),\n",
    "    class_mode = 'binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bc01a156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/13\n",
      "86/86 [==============================] - 153s 2s/step - loss: 0.5489 - acc: 0.7541\n",
      "Epoch 2/13\n",
      "86/86 [==============================] - 146s 2s/step - loss: 0.3720 - acc: 0.8502\n",
      "Epoch 3/13\n",
      "86/86 [==============================] - 144s 2s/step - loss: 0.2790 - acc: 0.8886\n",
      "Epoch 4/13\n",
      "86/86 [==============================] - 108s 1s/step - loss: 0.2439 - acc: 0.9014\n",
      "Epoch 5/13\n",
      "86/86 [==============================] - 98s 1s/step - loss: 0.2143 - acc: 0.9182\n",
      "Epoch 6/13\n",
      "86/86 [==============================] - 98s 1s/step - loss: 0.1684 - acc: 0.9339\n",
      "Epoch 7/13\n",
      "86/86 [==============================] - 99s 1s/step - loss: 0.1472 - acc: 0.9448\n",
      "Epoch 8/13\n",
      "86/86 [==============================] - 98s 1s/step - loss: 0.1163 - acc: 0.9551\n",
      "Epoch 9/13\n",
      "86/86 [==============================] - 100s 1s/step - loss: 0.0972 - acc: 0.9624\n",
      "Epoch 10/13\n",
      "86/86 [==============================] - 102s 1s/step - loss: 0.1008 - acc: 0.9635\n",
      "Epoch 11/13\n",
      "86/86 [==============================] - 148s 2s/step - loss: 0.0930 - acc: 0.9700\n",
      "Epoch 12/13\n",
      "86/86 [==============================] - 99s 1s/step - loss: 0.0792 - acc: 0.9799\n",
      "Epoch 13/13\n",
      "86/86 [==============================] - 98s 1s/step - loss: 0.0824 - acc: 0.9759\n"
     ]
    }
   ],
   "source": [
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "hist = model.fit(\n",
    "    train_gen,\n",
    "    epochs = 13,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "393efeb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://f38d81b2-f27f-458e-b578-29eaaaba54fa/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://f38d81b2-f27f-458e-b578-29eaaaba54fa/assets\n"
     ]
    }
   ],
   "source": [
    "with open('clf.pickle', 'wb') as f:\n",
    "    pickle.dump(hist, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11baa164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints', 'clf.pickle', 'Dataset', 'temp', 'Untitled.ipynb']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "263e1ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.save(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1d9fcba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './model.h5'\n",
    "loaded_model= tf.keras.models.load_model(path )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "952bd3fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.engine.sequential.Sequential"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1a2b03bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detection(files):\n",
    "  limit = 0\n",
    "  for myFiles in files:\n",
    "#     path = '/content/' + myFiles\n",
    "    img = tf.keras.utils.load_img(myFiles, target_size=(300, 300))\n",
    "    \n",
    "#     cv2.imshow(\"iframe\",img)\n",
    "    x = tf.keras.utils.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    images = np.vstack([x])\n",
    "    classes = loaded_model.predict(images)\n",
    "    print(classes[0])\n",
    "    if classes[0]>0.5:\n",
    "      print(\"Miscellaneous movement\")\n",
    "    else:\n",
    "      print(\"Movement by Animal\")\n",
    "      limit = limit + 1\n",
    "  if limit > 3:\n",
    "#     display(IPython.display.Audio(alarm, autoplay=True))\n",
    "    print(\"Animal detected\")\n",
    "  else:\n",
    "    print(\"No animal detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b688d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "551ad475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7380343675613403,\n",
       " 0.8268176913261414,\n",
       " 0.877237856388092,\n",
       " 0.9115820527076721,\n",
       " 0.9331384897232056,\n",
       " 0.9422725439071655,\n",
       " 0.9503105878829956,\n",
       " 0.9568871259689331,\n",
       " 0.9641943573951721,\n",
       " 0.9663865566253662,\n",
       " 0.9689440727233887,\n",
       " 0.9758859872817993,\n",
       " 0.975520670413971]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist.history['acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08eb96c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'history'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12828\\3476780382.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"loss\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"model accuracy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'history'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(hist.history[\"loss\"])\n",
    "plt.plot(hist.history['acc'])\n",
    "plt.title(\"model accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Loss\",\"Accuracy\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "08a4ae1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def animalEnc(video):\n",
    "  cap = cv2.VideoCapture(video)\n",
    "\n",
    "  kernel= None\n",
    "\n",
    "  foog = cv2.createBackgroundSubtractorMOG2(detectShadows = True, varThreshold = 50, history = 500)\n",
    "\n",
    "  thresh = 1100\n",
    "  count = 0\n",
    "  detect_thresh = 7\n",
    "  currentframe = 0\n",
    "  disp=[]\n",
    "  while(1):\n",
    "      ret, frame = cap.read()\n",
    "      if not ret:\n",
    "          break    \n",
    "      fgmask = foog.apply(frame)\n",
    "\n",
    "      ret, fgmask = cv2.threshold(fgmask, 250, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "      fgmask = cv2.erode(fgmask,kernel,iterations = 1)\n",
    "      fgmask = cv2.dilate(fgmask,kernel,iterations = 1)\n",
    "      \n",
    "      contours, hierarchy = cv2.findContours(fgmask,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "      \n",
    "      if contours:\n",
    "\n",
    "          cnt = max(contours, key = cv2.contourArea)\n",
    "          if cv2.contourArea(cnt) > thresh:\n",
    "\n",
    "              x,y,w,h = cv2.boundingRect(cnt)\n",
    "              cv2.rectangle(frame,(x ,y),(x+w,y+h),(0,0,255),2)\n",
    "              cv2.putText(frame,'Movement Detected',(x,y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.3, (0,255,0), 1, cv2.LINE_AA)\n",
    "              count = count + 1\n",
    "              cv2.imwrite(os.path.join('C:/Users/Likhita/OneDrive - XLRI/Desktop/sem 7/Project/temp','frame'+str(currentframe)+'.jpg'),frame)\n",
    "              currentframe+=1\n",
    "\n",
    "      fgmask_3 = cv2.cvtColor(fgmask, cv2.COLOR_GRAY2BGR)\n",
    "      stacked = np.hstack((fgmask_3,frame))\n",
    "      \n",
    "      cv2.imshow(\"rame\",cv2.resize(stacked,None,fx=0.65,fy=0.65))\n",
    "      \n",
    "#       files = cv2.imread(r\"C:/Users/Likhita/OneDrive - XLRI/Desktop/sem 7/Project/temp\")\n",
    "      \n",
    "      files=[]\n",
    "      if count>detect_thresh:\n",
    "        for img in glob.glob(\"C:/Users/Likhita/OneDrive - XLRI/Desktop/sem 7/Project/temp/*.jpg\"):\n",
    "#             //n= cv2.imread(img)\n",
    "            files.append(img)\n",
    "        print(\"invoking\", len(files))\n",
    "        detection(files)\n",
    "        break\n",
    "      k = cv2.waitKey(40) & 0xff\n",
    "      if k == ord('q'):\n",
    "          break\n",
    "\n",
    "  cap.release()\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "fa30e71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invoking 8\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "[0.]\n",
      "Movement by Animal\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "[0.]\n",
      "Movement by Animal\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "[0.]\n",
      "Movement by Animal\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "[0.]\n",
      "Movement by Animal\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "[0.]\n",
      "Movement by Animal\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "[0.]\n",
      "Movement by Animal\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "[0.]\n",
      "Movement by Animal\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "[0.]\n",
      "Movement by Animal\n",
      "Animal detected\n"
     ]
    }
   ],
   "source": [
    "animalEnc(r\"C:\\Users\\Likhita\\OneDrive - XLRI\\Desktop\\sem 7\\Project\\fh9.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "fd91da1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9dee17",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(r\"C:\\Users\\Likhita\\OneDrive - XLRI\\Desktop\\sem 7\\Project\\el.JPG\")\n",
    "cv2.imshow(\"frame\", img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e861201",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
